# Streaming Platform

[![CI](https://github.com/mohammedadnansohail1-pixel/streaming-platform/actions/workflows/ci.yml/badge.svg)](https://github.com/mohammedadnansohail1-pixel/streaming-platform/actions/workflows/ci.yml)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Production-grade, config-driven streaming data platform with CDC support.**

## âœ¨ Features

- **ğŸ”§ Config-Driven** - Define domains in YAML, no code changes needed
- **ğŸ“Š Real-Time Analytics** - Sub-second aggregations with Spark Structured Streaming
- **ğŸ”„ CDC (Change Data Capture)** - Capture database changes with Debezium
- **ğŸ“‹ Schema Evolution** - Avro + Schema Registry for safe schema changes
- **ğŸ“ˆ Full Observability** - Prometheus metrics + Grafana dashboards
- **ğŸ”Œ Pluggable Sinks** - ClickHouse, PostgreSQL, extensible base class
- **ğŸ” Secure Secrets** - Registry pattern with env/file/vault backends
- **âœ… Production Ready** - 92 unit tests, CI/CD, health checks

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            DATA SOURCES                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         PostgreSQL               â”‚           Synthetic Generator              â”‚
â”‚         (CDC Source)             â”‚           (Event Generator)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                         â”‚
             â–¼                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚       Debezium         â”‚                            â”‚
â”‚   (Change Data Capture)â”‚                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
             â”‚                                         â”‚
             â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              KAFKA + SCHEMA REGISTRY                          â”‚
â”‚                        (Message Broker + Schema Management)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          SPARK STRUCTURED STREAMING                           â”‚
â”‚              (Windowed Aggregations, Watermarks, Checkpointing)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   ClickHouse    â”‚               â”‚   PostgreSQL    â”‚
          â”‚   (Analytics)   â”‚               â”‚ (Transactional) â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                 â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PROMETHEUS + GRAFANA (Monitoring)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### One-Command Setup
```bash
# Clone
git clone https://github.com/mohammedadnansohail1-pixel/streaming-platform.git
cd streaming-platform

# Start all infrastructure
docker compose -f docker/docker-compose.yml up -d

# Setup Python
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env

# Check all services
./streaming-cli health
```

### Expected Output
```
âœ“ Config loaded (ecommerce)
âœ“ Schemas generated (6 event types)
âœ“ Kafka connected (7 topics)
âœ“ Schema Registry connected (0 subjects)
âœ“ ClickHouse connected
âœ“ PostgreSQL connected
âœ“ Debezium connected (1 connectors)
```

### Service URLs

| Service | URL | Credentials |
|---------|-----|-------------|
| Grafana | http://localhost:3000 | admin / streaming123 |
| Prometheus | http://localhost:9090 | - |
| Schema Registry | http://localhost:8081 | - |
| ClickHouse | http://localhost:8123 | default / streaming123 |
| Debezium | http://localhost:8083 | - |

## ğŸ“ Project Structure
```
streaming-platform/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ platform.yaml           # Kafka, Spark, sinks config
â”‚   â””â”€â”€ domains/
â”‚       â”œâ”€â”€ ecommerce.yaml      # E-commerce events
â”‚       â”œâ”€â”€ iot.yaml            # IoT sensor events
â”‚       â””â”€â”€ fintech.yaml        # Financial transactions
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config/                 # Config loader + secret resolution
â”‚   â”œâ”€â”€ schema/                 # Avro schema generator
â”‚   â””â”€â”€ secrets/                # Pluggable secrets backends
â”œâ”€â”€ generators/                 # Synthetic data generation
â”œâ”€â”€ sources/                    # Kafka producer
â”œâ”€â”€ spark/                      # Streaming jobs
â”œâ”€â”€ sinks/                      # ClickHouse, PostgreSQL
â”œâ”€â”€ cdc/                        # Debezium CDC consumer
â”œâ”€â”€ monitoring/                 # Prometheus + Grafana
â”œâ”€â”€ cli/                        # Command-line interface
â”œâ”€â”€ docker/                     # All-in-one Docker Compose
â””â”€â”€ tests/                      # 92 unit tests
```

## ğŸ–¥ï¸ CLI Commands
```bash
# List available domains
./streaming-cli domains

# Show configuration
./streaming-cli config --domain ecommerce

# Check all services health
./streaming-cli health

# Generate and send events to Kafka
./streaming-cli generate --domain ecommerce --event-type page_view --count 100

# Show Avro schema
./streaming-cli schema --event-type purchase

# Run Spark streaming job
./streaming-cli run --domain ecommerce --event-type page_view --aggregation events_per_minute
```

## ğŸ”„ CDC (Change Data Capture)

Capture real-time database changes with Debezium:
```bash
# Test CDC - watch INSERT/UPDATE/DELETE events
python scripts/test_cdc.py
```

Output:
```
â• INSERT   | customers    | {'id': 1, 'name': 'Jane Smith', ...}
ğŸ“ UPDATE   | customers    | {'id': 1, 'name': 'Jane Doe', ...}
â• INSERT   | orders       | {'id': 1, 'amount_cents': 9999, ...}
ğŸ“ UPDATE   | orders       | {'id': 1, 'status': 'completed', ...}
âŒ DELETE   | orders       | {'id': 1, ...}
```

## ğŸ¯ Use Cases

| Domain | Event Types | Aggregations |
|--------|-------------|--------------|
| **E-Commerce** | page_view, add_to_cart, purchase | events_per_minute, revenue_per_hour |
| **IoT** | sensor_reading, alert, device_status | avg_temperature, alerts_by_severity |
| **Fintech** | transaction, login, fraud_alert | transaction_volume, failed_logins |

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Message Broker | Apache Kafka 7.5 |
| Schema Registry | Confluent Schema Registry |
| Stream Processing | Spark Structured Streaming 3.5 |
| CDC | Debezium 2.5 |
| Serialization | Apache Avro |
| Analytics DB | ClickHouse |
| Transactional DB | PostgreSQL 16 |
| Monitoring | Prometheus + Grafana |
| Language | Python 3.12 |

## ğŸ“ˆ Performance

| Metric | Value |
|--------|-------|
| Producer Throughput | 50K events/sec |
| End-to-End Latency | < 500ms |
| CDC Latency | < 100ms |
| Spark Batch Processing | 100K events/sec |

## ğŸ§ª Testing
```bash
# Run all tests (92 tests)
pytest tests/unit/ -v

# With coverage
pytest tests/unit/ --cov=core --cov=generators --cov=sources --cov=spark --cov=sinks --cov=monitoring --cov=cdc

# Lint
ruff check . && black --check .
```

## ğŸ“š Documentation

- [Architecture & Design Decisions](docs/ARCHITECTURE.md)
- [Setup Guide](docs/SETUP.md)
- [API Reference](docs/API.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ‘¤ Author

**Adnan** - Data Engineer

Building production-grade streaming systems for real-time analytics.

---

<p align="center">
  <b>â­ Star this repo if you find it useful!</b>
</p>

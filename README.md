# Streaming Platform

[![CI](https://github.com/mohammedadnansohail1-pixel/streaming-platform/actions/workflows/ci.yml/badge.svg)](https://github.com/mohammedadnansohail1-pixel/streaming-platform/actions/workflows/ci.yml)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Production-grade, config-driven streaming data platform for real-time event processing.**

<p align="center">
  <img src="docs/images/architecture.png" alt="Architecture" width="800">
</p>

## âœ¨ Features

- **ğŸ”§ Config-Driven** - Define domains in YAML, no code changes needed
- **ğŸ“Š Real-Time Analytics** - Sub-second aggregations with Spark Structured Streaming
- **ğŸ”„ Schema Evolution** - Avro + Schema Registry for safe schema changes
- **ğŸ“ˆ Full Observability** - Prometheus metrics + Grafana dashboards
- **ğŸ”Œ Pluggable Sinks** - ClickHouse, PostgreSQL, extensible base class
- **ğŸ” Secure Secrets** - Registry pattern with env/file/vault backends
- **âœ… Production Ready** - 68 unit tests, CI/CD, health checks

## ğŸš€ Quick Start

### One-Command Setup
```bash
# Clone
git clone https://github.com/mohammedadnansohail1-pixel/streaming-platform.git
cd streaming-platform

# Start all infrastructure
docker compose -f docker/docker-compose.yml up -d

# Setup Python
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env

# Run the demo
python scripts/test_clickhouse_sink.py
```

### What You'll See
```
âœ“ Events flowing: Kafka â†’ Spark â†’ ClickHouse
âœ“ Real-time aggregations by device type
âœ“ Data persisted to ClickHouse
```

**Service URLs:**
| Service | URL | Credentials |
|---------|-----|-------------|
| Grafana | http://localhost:3000 | admin / streaming123 |
| Prometheus | http://localhost:9090 | - |
| Schema Registry | http://localhost:8081 | - |
| ClickHouse | http://localhost:8123 | default / streaming123 |

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Synthetic  â”‚â”€â”€â”€â”€â–¶â”‚  Kafka  â”‚â”€â”€â”€â”€â–¶â”‚ Spark Streaming â”‚â”€â”€â”€â”€â–¶â”‚ ClickHouse â”‚
â”‚  Generator  â”‚     â”‚ + Avro  â”‚     â”‚  (Aggregations) â”‚     â”‚ (Analytics)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                   â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Config-Driven     â”‚
                         â”‚   (YAML + Secrets)  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure
```
streaming-platform/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ platform.yaml           # Kafka, Spark, sinks config
â”‚   â””â”€â”€ domains/
â”‚       â””â”€â”€ ecommerce.yaml      # Domain events & aggregations
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config/                 # Config loader + secret resolution
â”‚   â”œâ”€â”€ schema/                 # Avro schema generator
â”‚   â””â”€â”€ secrets/                # Pluggable secrets backends
â”œâ”€â”€ generators/                 # Synthetic data generation
â”œâ”€â”€ sources/                    # Kafka producer
â”œâ”€â”€ spark/                      # Streaming jobs
â”œâ”€â”€ sinks/                      # ClickHouse, PostgreSQL
â”œâ”€â”€ monitoring/                 # Prometheus + Grafana
â”œâ”€â”€ docker/                     # All-in-one Docker Compose
â””â”€â”€ tests/                      # 68 unit tests
```

## ğŸ¯ Use Cases

**E-Commerce**
```yaml
event_types:
  - page_view, add_to_cart, purchase
aggregations:
  - events_per_minute by device_type
  - revenue_per_hour by currency
```

**IoT**
```yaml
event_types:
  - sensor_reading, alert, device_status
aggregations:
  - avg_temperature per 5 minutes
  - anomaly_count by device_id
```

**Fintech**
```yaml
event_types:
  - transaction, login, fraud_alert
aggregations:
  - transaction_volume per minute
  - unique_users per hour
```

## ğŸ“Š Adding a New Domain

No code changes needed! Just create a YAML config:
```yaml
# config/domains/gaming.yaml
domain: gaming
entity:
  primary_key: player_id

event_types:
  - name: player_action
    attributes:
      - action_type
      - game_level
    dimensions:
      - platform
      - region

aggregations:
  - name: actions_per_minute
    type: count
    window:
      type: tumbling
      duration: 1 minute
    group_by:
      - platform
```

Then run:
```python
config = loader.load(domain="gaming")
```

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Message Broker | Apache Kafka 7.5 |
| Schema Registry | Confluent Schema Registry |
| Stream Processing | Spark Structured Streaming 3.5 |
| Serialization | Apache Avro |
| Analytics DB | ClickHouse |
| Transactional DB | PostgreSQL 16 |
| Monitoring | Prometheus + Grafana |
| Language | Python 3.12 |

## ğŸ“ˆ Performance

| Metric | Value |
|--------|-------|
| Producer Throughput | 50K events/sec |
| End-to-End Latency | < 500ms |
| Spark Batch Processing | 100K events/sec |
| ClickHouse Ingestion | 500K rows/sec |

## ğŸ§ª Testing
```bash
# Run all tests
pytest tests/unit/ -v

# With coverage
pytest tests/unit/ --cov=core --cov=generators --cov=sources --cov=spark --cov=sinks

# Lint
ruff check .
black --check .
```

## ğŸ“š Documentation

- [Architecture & Design Decisions](docs/ARCHITECTURE.md)
- [Setup Guide](docs/SETUP.md)
- [API Reference](docs/API.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ‘¤ Author

**Adnan** - Data Engineering

- Building production-grade streaming systems
- Available for freelance projects
- [LinkedIn]([https://linkedin.com/in/yourprofile](https://www.linkedin.com/in/adnan21/)) | [Email](mohammedadnansohai11@gmail.com)

---

<p align="center">
  <b>â­ Star this repo if you find it useful!</b>
</p>
